{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-13T09:53:37.740990Z","iopub.status.busy":"2024-04-13T09:53:37.739912Z","iopub.status.idle":"2024-04-13T09:53:37.785402Z","shell.execute_reply":"2024-04-13T09:53:37.784064Z","shell.execute_reply.started":"2024-04-13T09:53:37.740957Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:37.788321Z","iopub.status.busy":"2024-04-13T09:53:37.787165Z","iopub.status.idle":"2024-04-13T09:53:38.114038Z","shell.execute_reply":"2024-04-13T09:53:38.112249Z","shell.execute_reply.started":"2024-04-13T09:53:37.788285Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('./merged_twitter.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.116010Z","iopub.status.busy":"2024-04-13T09:53:38.115625Z","iopub.status.idle":"2024-04-13T09:53:38.129153Z","shell.execute_reply":"2024-04-13T09:53:38.128053Z","shell.execute_reply.started":"2024-04-13T09:53:38.115974Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fun</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Soooo high</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Both of you</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Wow... u just became cooler.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>as much as i love to be hopeful, i reckon the ...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>like</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>DANGERously</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>test test from the LG enV2</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        selected_text sentiment\n","0                 I`d have responded, if I were going   neutral\n","1                                            Sooo SAD  negative\n","2                                         bullying me  negative\n","3                                      leave me alone  negative\n","4                                       Sons of ****,  negative\n","5   http://www.dothebouncy.com/smf - some shameles...   neutral\n","6                                                 fun  positive\n","7                                          Soooo high   neutral\n","8                                         Both of you   neutral\n","9                        Wow... u just became cooler.  positive\n","10  as much as i love to be hopeful, i reckon the ...   neutral\n","11                                               like  positive\n","12                                        DANGERously  negative\n","13                                               lost  negative\n","14                         test test from the LG enV2   neutral"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head(15)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.131032Z","iopub.status.busy":"2024-04-13T09:53:38.130572Z","iopub.status.idle":"2024-04-13T09:53:38.146650Z","shell.execute_reply":"2024-04-13T09:53:38.144858Z","shell.execute_reply.started":"2024-04-13T09:53:38.130994Z"},"trusted":true},"outputs":[{"data":{"text/plain":["190461"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.150332Z","iopub.status.busy":"2024-04-13T09:53:38.149962Z","iopub.status.idle":"2024-04-13T09:53:38.186137Z","shell.execute_reply":"2024-04-13T09:53:38.184769Z","shell.execute_reply.started":"2024-04-13T09:53:38.150303Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["selected_text    68\n","sentiment         7\n","dtype: int64\n"]}],"source":["print(df.isnull().sum())\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.189450Z","iopub.status.busy":"2024-04-13T09:53:38.188741Z","iopub.status.idle":"2024-04-13T09:53:38.229459Z","shell.execute_reply":"2024-04-13T09:53:38.228429Z","shell.execute_reply.started":"2024-04-13T09:53:38.189403Z"},"trusted":true},"outputs":[],"source":["df_dropped = df.dropna(inplace = True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.231520Z","iopub.status.busy":"2024-04-13T09:53:38.231154Z","iopub.status.idle":"2024-04-13T09:53:38.261551Z","shell.execute_reply":"2024-04-13T09:53:38.260107Z","shell.execute_reply.started":"2024-04-13T09:53:38.231487Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["selected_text    0\n","sentiment        0\n","dtype: int64\n"]}],"source":["print(df.isnull().sum())\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.263236Z","iopub.status.busy":"2024-04-13T09:53:38.262912Z","iopub.status.idle":"2024-04-13T09:53:38.285601Z","shell.execute_reply":"2024-04-13T09:53:38.283819Z","shell.execute_reply.started":"2024-04-13T09:53:38.263212Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['neutral', 'negative', 'positive'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['sentiment'].unique()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.288691Z","iopub.status.busy":"2024-04-13T09:53:38.288289Z","iopub.status.idle":"2024-04-13T09:53:38.463516Z","shell.execute_reply":"2024-04-13T09:53:38.461656Z","shell.execute_reply.started":"2024-04-13T09:53:38.288661Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>selected_text</th>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>negative</th>\n","      <td>40792</td>\n","    </tr>\n","    <tr>\n","      <th>neutral</th>\n","      <td>64190</td>\n","    </tr>\n","    <tr>\n","      <th>positive</th>\n","      <td>76393</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           selected_text\n","sentiment               \n","negative           40792\n","neutral            64190\n","positive           76393"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('sentiment').nunique()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.465564Z","iopub.status.busy":"2024-04-13T09:53:38.465101Z","iopub.status.idle":"2024-04-13T09:53:38.491299Z","shell.execute_reply":"2024-04-13T09:53:38.489873Z","shell.execute_reply.started":"2024-04-13T09:53:38.465523Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                       selected_text sentiment\n","0                I`d have responded, if I were going   neutral\n","1                                           Sooo SAD  negative\n","2                                        bullying me  negative\n","3                                     leave me alone  negative\n","4                                      Sons of ****,  negative\n","5  http://www.dothebouncy.com/smf - some shameles...   neutral\n","6                                                fun  positive\n","7                                         Soooo high   neutral\n","8                                        Both of you   neutral\n","9                       Wow... u just became cooler.  positive\n","                                            selected_text sentiment\n","190451  raga knows dat wont spared modi courts cheatin...  positive\n","190452  congress veteran sudhakar reddy joins bjp meet...   neutral\n","190453  engine growth modi unveils indias first 12000 ...  positive\n","190454  modi promised 2014 lok sabha elections best or...  positive\n","190455  save agenda peddling â€™ terror attacks every se...   neutral\n","190456  456 crores paid neerav modi recovered congress...  negative\n","190457  dear rss terrorist payal gawar modi killing 10...  negative\n","190458                       cover interaction forum left   neutral\n","190459  big project came india modi dream project happ...   neutral\n","190460  ever listen like gurukul discipline maintained...  positive\n"]}],"source":["df = df[['selected_text', 'sentiment']]\n","print(df.head(10))\n","print(df.tail(10))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.494296Z","iopub.status.busy":"2024-04-13T09:53:38.493725Z","iopub.status.idle":"2024-04-13T09:53:38.534118Z","shell.execute_reply":"2024-04-13T09:53:38.532359Z","shell.execute_reply.started":"2024-04-13T09:53:38.494246Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df['selected_text'].isnull().sum()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.537091Z","iopub.status.busy":"2024-04-13T09:53:38.535630Z","iopub.status.idle":"2024-04-13T09:53:38.569137Z","shell.execute_reply":"2024-04-13T09:53:38.567197Z","shell.execute_reply.started":"2024-04-13T09:53:38.537042Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Done\n"]}],"source":["df['selected_text'].fillna(\"No content\", inplace = True)\n","print(\"Done\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:53:38.570562Z","iopub.status.busy":"2024-04-13T09:53:38.570262Z","iopub.status.idle":"2024-04-13T09:54:09.043806Z","shell.execute_reply":"2024-04-13T09:54:09.042096Z","shell.execute_reply.started":"2024-04-13T09:53:38.570537Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From d:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Dhananjay\\AppData\\Local\\Temp\\ipykernel_4608\\2241134619.py:16: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  text = BeautifulSoup(text, 'html.parser').get_text()\n"]},{"name":"stdout","output_type":"stream","text":["                                            selected_text sentiment\n","0                                         responded going   neutral\n","1                                                sooo sad  negative\n","2                                                bullying  negative\n","3                                             leave alone  negative\n","4                                                    sons  negative\n","...                                                   ...       ...\n","190456  456 crores paid neerav modi recovered congress...  negative\n","190457  dear rss terrorist payal gawar modi killing 10...  negative\n","190458                       cover interaction forum left   neutral\n","190459  big project came india modi dream project happ...   neutral\n","190460  ever listen like gurukul discipline maintained...  positive\n","\n","[190386 rows x 2 columns]\n","[[   0    0    0 ...    0 4247   74]\n"," [   0    0    0 ...    0 3977  442]\n"," [   0    0    0 ...    0    0    0]\n"," ...\n"," [   0    0    0 ... 1573 2599  295]\n"," [   0    0    0 ...  474  284  526]\n"," [   0    0    0 ...   50  386  111]]\n"]}],"source":["import re\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pickle\n","\n","def preprocess_text(texts):\n","    preprocessed_texts = []\n","    stop_words = set(stopwords.words('english'))\n","    \n","    for text in texts:\n","        # Remove HTML tags\n","        text = BeautifulSoup(text, 'html.parser').get_text()\n","\n","        # Remove URLs\n","        text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n","\n","        # Tokenize text\n","        tokenizer = TweetTokenizer()\n","        tokens = tokenizer.tokenize(text)\n","\n","        # Remove emails\n","        tokens = [token for token in tokens if not re.match(r'\\S+@\\S+', token)]\n","\n","        # Remove new lines characters\n","        tokens = [token for token in tokens if token != '\\n']\n","\n","        # Remove distracting single quotes\n","        tokens = [token.replace(\"'\", \"\") for token in tokens]\n","\n","        # Remove all punctuation signs and stopwords\n","        tokens = [token.lower() for token in tokens if token.isalnum() and token.lower() not in stop_words]\n","\n","        # Detokenize text\n","        preprocessed_texts.append(' '.join(tokens))\n","\n","    return np.array(preprocessed_texts)\n","# Preprocess 'tweet' column\n","df['selected_text'] = preprocess_text(df['selected_text'])\n","\n","print(df)\n","\n","df['sentiment'] = df['sentiment'].replace({'negative': 0, 'positive': 1, 'neutral': 2})\n","\n","max_words = 5000\n","max_len = 200\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(df['selected_text'])\n","\n","with open('tokenizer.pkl', 'wb') as f:\n","    pickle.dump(tokenizer, f)\n","\n","# Print the first most frequent words\n","\n","\n","sequences = tokenizer.texts_to_sequences(df['selected_text'])\n","X = pad_sequences(sequences, maxlen=max_len)\n","\n","# Convert sentiment column to numpy array\n","y = np.array(df['sentiment'])\n","\n","print(X)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:54:09.047969Z","iopub.status.busy":"2024-04-13T09:54:09.047592Z","iopub.status.idle":"2024-04-13T09:54:09.054780Z","shell.execute_reply":"2024-04-13T09:54:09.053609Z","shell.execute_reply.started":"2024-04-13T09:54:09.047938Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[2 0 0 ... 2 2 1]\n"]}],"source":["print(y)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:54:09.056220Z","iopub.status.busy":"2024-04-13T09:54:09.055915Z","iopub.status.idle":"2024-04-13T09:54:09.132495Z","shell.execute_reply":"2024-04-13T09:54:09.130999Z","shell.execute_reply.started":"2024-04-13T09:54:09.056193Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size: 152308\n","Test set size: 38078\n","Train labels size: 152308\n","Test labels size: 38078\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Splitting the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","print(\"Train set size:\", len(X_train))\n","print(\"Test set size:\", len(X_test))\n","print(\"Train labels size:\", len(y_train))\n","print(\"Test labels size:\", len(y_test))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T09:54:09.134450Z","iopub.status.busy":"2024-04-13T09:54:09.134091Z","iopub.status.idle":"2024-04-13T11:15:02.471498Z","shell.execute_reply":"2024-04-13T11:15:02.469903Z","shell.execute_reply.started":"2024-04-13T09:54:09.134412Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"," 51/952 [>.............................] - ETA: 55:14 - loss: 1.0647 - accuracy: 0.4412"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train your model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save the model as .h5 file\u001b[39;00m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model2.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n","File \u001b[1;32md:\\Final Year Project\\Project(latest)\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","\n","# Compute class weights\n","class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n","class_weights_dict = dict(enumerate(class_weights))\n","\n","# Define your neural network model\n","model = Sequential()\n","model.add(Embedding(input_dim=max_words, output_dim=128))\n","model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n","model.add(Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3)))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3, activation='softmax'))\n","\n","# Compile your model with a lower learning rate\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Train your model\n","history = model.fit(X_train, y_train, batch_size=128, epochs=5, validation_split=0.2, class_weight=class_weights_dict)\n","\n","# Save the model as .h5 file\n","model.save(\"best_model2.h5\")\n","\n","# Evaluate your model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-13T11:15:02.472973Z","iopub.status.idle":"2024-04-13T11:15:02.473672Z","shell.execute_reply":"2024-04-13T11:15:02.473467Z","shell.execute_reply.started":"2024-04-13T11:15:02.473446Z"},"trusted":true},"outputs":[],"source":["# Function to preprocess a single text\n","def preprocess_single_text(text):\n","    stop_words = set(stopwords.words('english'))\n","\n","    # Remove HTML tags\n","    text = BeautifulSoup(text, 'html.parser').get_text()\n","\n","    # Remove URLs\n","    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n","\n","    # Tokenize text\n","    tokenizer = TweetTokenizer()\n","    tokens = tokenizer.tokenize(text)\n","\n","    # Remove emails\n","    tokens = [token for token in tokens if not re.match(r'\\S+@\\S+', token)]\n","\n","    # Remove new lines characters\n","    tokens = [token for token in tokens if token != '\\n']\n","\n","    # Remove distracting single quotes\n","    tokens = [token.replace(\"'\", \"\") for token in tokens]\n","\n","    # Remove all punctuation signs and stopwords\n","    tokens = [token.lower() for token in tokens if token.isalnum() and token.lower() not in stop_words]\n","\n","    # Detokenize text\n","    preprocessed_text = ' '.join(tokens)\n","\n","    return preprocessed_text\n","\n","# Preprocess a single text\n","text_to_classify = \"I was really disappointed with this product. It didn't live up to the hype at all. The quality was subpar, and it broke within a week of use. Definitely not worth the money.\"\n","preprocessed_text = preprocess_single_text(text_to_classify)\n","\n","# Tokenize and pad the preprocessed text\n","sequence = tokenizer.texts_to_sequences([preprocessed_text])\n","padded_sequence = pad_sequences(sequence, maxlen=max_len)\n","\n","# Predict the sentiment class\n","predicted_class = np.argmax(model.predict(padded_sequence), axis=-1)[0]\n","\n","# Map predicted class to sentiment label\n","sentiment_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n","predicted_sentiment = sentiment_mapping[predicted_class]\n","\n","print(\"Predicted Sentiment:\", predicted_sentiment)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-13T11:15:02.475009Z","iopub.status.idle":"2024-04-13T11:15:02.475677Z","shell.execute_reply":"2024-04-13T11:15:02.475489Z","shell.execute_reply.started":"2024-04-13T11:15:02.475471Z"},"trusted":true},"outputs":[],"source":["print(\"TensorFlow version:\", tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4771766,"sourceId":8083879,"sourceType":"datasetVersion"},{"datasetId":4775453,"sourceId":8089166,"sourceType":"datasetVersion"},{"datasetId":4783868,"sourceId":8100772,"sourceType":"datasetVersion"},{"datasetId":4785653,"sourceId":8103271,"sourceType":"datasetVersion"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
