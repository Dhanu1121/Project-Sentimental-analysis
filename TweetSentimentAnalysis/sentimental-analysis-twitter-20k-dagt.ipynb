{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-11T12:30:50.063808Z","iopub.status.busy":"2024-04-11T12:30:50.063307Z","iopub.status.idle":"2024-04-11T12:30:51.256564Z","shell.execute_reply":"2024-04-11T12:30:51.255304Z","shell.execute_reply.started":"2024-04-11T12:30:50.063769Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/twitter-dataset/train.csv\n","/kaggle/input/test-data/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.259185Z","iopub.status.busy":"2024-04-11T12:30:51.258735Z","iopub.status.idle":"2024-04-11T12:30:51.411447Z","shell.execute_reply":"2024-04-11T12:30:51.410317Z","shell.execute_reply.started":"2024-04-11T12:30:51.259157Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('/kaggle/input/twitter-dataset/train.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.413316Z","iopub.status.busy":"2024-04-11T12:30:51.412896Z","iopub.status.idle":"2024-04-11T12:30:51.436408Z","shell.execute_reply":"2024-04-11T12:30:51.435275Z","shell.execute_reply.started":"2024-04-11T12:30:51.413279Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>28b57f3990</td>\n","      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n","      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6e0c6d75b1</td>\n","      <td>2am feedings for the baby are fun when he is a...</td>\n","      <td>fun</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>50e14c0bb8</td>\n","      <td>Soooo high</td>\n","      <td>Soooo high</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>e050245fbd</td>\n","      <td>Both of you</td>\n","      <td>Both of you</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fc2cbefa9d</td>\n","      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n","      <td>Wow... u just became cooler.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2339a9b08b</td>\n","      <td>as much as i love to be hopeful, i reckon the...</td>\n","      <td>as much as i love to be hopeful, i reckon the ...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>16fab9f95b</td>\n","      <td>I really really like the song Love Story by Ta...</td>\n","      <td>like</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>74a76f6e0a</td>\n","      <td>My Sharpie is running DANGERously low on ink</td>\n","      <td>DANGERously</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>04dd1d2e34</td>\n","      <td>i want to go to music tonight but i lost my vo...</td>\n","      <td>lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>bbe3cbf620</td>\n","      <td>test test from the LG enV2</td>\n","      <td>test test from the LG enV2</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        textID                                               text  \\\n","0   cb774db0d1                I`d have responded, if I were going   \n","1   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2   088c60f138                          my boss is bullying me...   \n","3   9642c003ef                     what interview! leave me alone   \n","4   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","5   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n","6   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n","7   50e14c0bb8                                         Soooo high   \n","8   e050245fbd                                        Both of you   \n","9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n","10  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n","11  16fab9f95b  I really really like the song Love Story by Ta...   \n","12  74a76f6e0a       My Sharpie is running DANGERously low on ink   \n","13  04dd1d2e34  i want to go to music tonight but i lost my vo...   \n","14  bbe3cbf620                         test test from the LG enV2   \n","\n","                                        selected_text sentiment  \n","0                 I`d have responded, if I were going   neutral  \n","1                                            Sooo SAD  negative  \n","2                                         bullying me  negative  \n","3                                      leave me alone  negative  \n","4                                       Sons of ****,  negative  \n","5   http://www.dothebouncy.com/smf - some shameles...   neutral  \n","6                                                 fun  positive  \n","7                                          Soooo high   neutral  \n","8                                         Both of you   neutral  \n","9                        Wow... u just became cooler.  positive  \n","10  as much as i love to be hopeful, i reckon the ...   neutral  \n","11                                               like  positive  \n","12                                        DANGERously  negative  \n","13                                               lost  negative  \n","14                         test test from the LG enV2   neutral  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head(15)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.439666Z","iopub.status.busy":"2024-04-11T12:30:51.439204Z","iopub.status.idle":"2024-04-11T12:30:51.447355Z","shell.execute_reply":"2024-04-11T12:30:51.446017Z","shell.execute_reply.started":"2024-04-11T12:30:51.439636Z"},"trusted":true},"outputs":[{"data":{"text/plain":["27481"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.449020Z","iopub.status.busy":"2024-04-11T12:30:51.448646Z","iopub.status.idle":"2024-04-11T12:30:51.469119Z","shell.execute_reply":"2024-04-11T12:30:51.468224Z","shell.execute_reply.started":"2024-04-11T12:30:51.448989Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['neutral', 'negative', 'positive'], dtype=object)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df['sentiment'].unique()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.471273Z","iopub.status.busy":"2024-04-11T12:30:51.470840Z","iopub.status.idle":"2024-04-11T12:30:51.527013Z","shell.execute_reply":"2024-04-11T12:30:51.526000Z","shell.execute_reply.started":"2024-04-11T12:30:51.471235Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>negative</th>\n","      <td>7781</td>\n","      <td>7781</td>\n","      <td>5861</td>\n","    </tr>\n","    <tr>\n","      <th>neutral</th>\n","      <td>11118</td>\n","      <td>11117</td>\n","      <td>11111</td>\n","    </tr>\n","    <tr>\n","      <th>positive</th>\n","      <td>8582</td>\n","      <td>8582</td>\n","      <td>5537</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           textID   text  selected_text\n","sentiment                              \n","negative     7781   7781           5861\n","neutral     11118  11117          11111\n","positive     8582   8582           5537"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('sentiment').nunique()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.528741Z","iopub.status.busy":"2024-04-11T12:30:51.528424Z","iopub.status.idle":"2024-04-11T12:30:51.543259Z","shell.execute_reply":"2024-04-11T12:30:51.542097Z","shell.execute_reply.started":"2024-04-11T12:30:51.528713Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         selected_text sentiment\n","0  I`d have responded, if I were going   neutral\n","1                             Sooo SAD  negative\n","2                          bullying me  negative\n","3                       leave me alone  negative\n","4                        Sons of ****,  negative"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = df[['selected_text', 'sentiment']]\n","df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.545039Z","iopub.status.busy":"2024-04-11T12:30:51.544660Z","iopub.status.idle":"2024-04-11T12:30:51.559850Z","shell.execute_reply":"2024-04-11T12:30:51.558519Z","shell.execute_reply.started":"2024-04-11T12:30:51.545011Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['selected_text'].isnull().sum()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.563523Z","iopub.status.busy":"2024-04-11T12:30:51.563080Z","iopub.status.idle":"2024-04-11T12:30:51.578493Z","shell.execute_reply":"2024-04-11T12:30:51.577688Z","shell.execute_reply.started":"2024-04-11T12:30:51.563489Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Done\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/2882932491.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['selected_text'].fillna(\"No content\", inplace = True)\n"]}],"source":["df['selected_text'].fillna(\"No content\", inplace = True)\n","print(\"Done\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:30:51.581679Z","iopub.status.busy":"2024-04-11T12:30:51.581347Z","iopub.status.idle":"2024-04-11T12:31:15.048365Z","shell.execute_reply":"2024-04-11T12:31:15.047284Z","shell.execute_reply.started":"2024-04-11T12:30:51.581652Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-11 12:30:56.369636: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-11 12:30:56.369802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-11 12:30:56.559664: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/tmp/ipykernel_33/2864154924.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  text = BeautifulSoup(text, 'html.parser').get_text()\n"]},{"name":"stdout","output_type":"stream","text":["                            selected_text sentiment\n","0                         responded going   neutral\n","1                                sooo sad  negative\n","2                                bullying  negative\n","3                             leave alone  negative\n","4                                    sons  negative\n","...                                   ...       ...\n","27476                                lost  negative\n","27477                               force  negative\n","27478                            yay good  positive\n","27479                               worth  positive\n","27480  flirting going atg smiles yay hugs   neutral\n","\n","[27481 rows x 2 columns]\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/2864154924.py:45: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['sentiment'] = df['sentiment'].replace({'negative': 0, 'positive': 1, 'neutral': 2})\n"]},{"name":"stdout","output_type":"stream","text":["[[   0    0    0 ...    0    0    9]\n"," [   0    0    0 ...    0  299   25]\n"," [   0    0    0 ...    0    0    0]\n"," ...\n"," [   0    0    0 ...    0  116    1]\n"," [   0    0    0 ...    0    0  451]\n"," [   0    0    0 ... 2327  116  560]]\n"]}],"source":["import re\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def preprocess_text(texts):\n","    preprocessed_texts = []\n","    stop_words = set(stopwords.words('english'))\n","    \n","    for text in texts:\n","        # Remove HTML tags\n","        text = BeautifulSoup(text, 'html.parser').get_text()\n","\n","        # Remove URLs\n","        text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n","\n","        # Tokenize text\n","        tokenizer = TweetTokenizer()\n","        tokens = tokenizer.tokenize(text)\n","\n","        # Remove emails\n","        tokens = [token for token in tokens if not re.match(r'\\S+@\\S+', token)]\n","\n","        # Remove new lines characters\n","        tokens = [token for token in tokens if token != '\\n']\n","\n","        # Remove distracting single quotes\n","        tokens = [token.replace(\"'\", \"\") for token in tokens]\n","\n","        # Remove all punctuation signs and stopwords\n","        tokens = [token.lower() for token in tokens if token.isalnum() and token.lower() not in stop_words]\n","\n","        # Detokenize text\n","        preprocessed_texts.append(' '.join(tokens))\n","\n","    return np.array(preprocessed_texts)\n","# Preprocess 'tweet' column\n","df['selected_text'] = preprocess_text(df['selected_text'])\n","\n","print(df)\n","\n","df['sentiment'] = df['sentiment'].replace({'negative': 0, 'positive': 1, 'neutral': 2})\n","\n","max_words = 5000\n","max_len = 200\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(df['selected_text'])\n","sequences = tokenizer.texts_to_sequences(df['selected_text'])\n","X = pad_sequences(sequences, maxlen=max_len)\n","\n","# Convert sentiment column to numpy array\n","y = np.array(df['sentiment'])\n","\n","print(X)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:31:15.051073Z","iopub.status.busy":"2024-04-11T12:31:15.049959Z","iopub.status.idle":"2024-04-11T12:31:15.058140Z","shell.execute_reply":"2024-04-11T12:31:15.056805Z","shell.execute_reply.started":"2024-04-11T12:31:15.050999Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[2 0 0 ... 1 1 2]\n"]}],"source":["print(y)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T12:31:15.059994Z","iopub.status.busy":"2024-04-11T12:31:15.059574Z","iopub.status.idle":"2024-04-11T12:31:15.102558Z","shell.execute_reply":"2024-04-11T12:31:15.101325Z","shell.execute_reply.started":"2024-04-11T12:31:15.059952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size: 21984\n","Test set size: 5497\n","Train labels size: 21984\n","Test labels size: 5497\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Splitting the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","print(\"Train set size:\", len(X_train))\n","print(\"Test set size:\", len(X_test))\n","print(\"Train labels size:\", len(y_train))\n","print(\"Test labels size:\", len(y_test))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T13:56:56.269065Z","iopub.status.busy":"2024-04-11T13:56:56.267612Z","iopub.status.idle":"2024-04-11T15:02:44.402380Z","shell.execute_reply":"2024-04-11T15:02:44.401244Z","shell.execute_reply.started":"2024-04-11T13:56:56.269015Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - accuracy: 0.4723 - loss: 0.9948\n","Epoch 1: val_accuracy improved from -inf to 0.72527, saving model to best_model.keras\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 937ms/step - accuracy: 0.4727 - loss: 0.9945 - val_accuracy: 0.7253 - val_loss: 0.7086\n","Epoch 2/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.7291 - loss: 0.6954\n","Epoch 2: val_accuracy improved from 0.72527 to 0.77234, saving model to best_model.keras\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 918ms/step - accuracy: 0.7291 - loss: 0.6953 - val_accuracy: 0.7723 - val_loss: 0.5820\n","Epoch 3/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874ms/step - accuracy: 0.8232 - loss: 0.4972\n","Epoch 3: val_accuracy improved from 0.77234 to 0.78485, saving model to best_model.keras\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 940ms/step - accuracy: 0.8232 - loss: 0.4972 - val_accuracy: 0.7849 - val_loss: 0.5462\n","Epoch 4/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859ms/step - accuracy: 0.8530 - loss: 0.4119\n","Epoch 4: val_accuracy improved from 0.78485 to 0.79986, saving model to best_model.keras\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 920ms/step - accuracy: 0.8529 - loss: 0.4120 - val_accuracy: 0.7999 - val_loss: 0.5479\n","Epoch 5/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878ms/step - accuracy: 0.8657 - loss: 0.3817\n","Epoch 5: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 944ms/step - accuracy: 0.8657 - loss: 0.3817 - val_accuracy: 0.7967 - val_loss: 0.5701\n","Epoch 6/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856ms/step - accuracy: 0.8777 - loss: 0.3476\n","Epoch 6: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 919ms/step - accuracy: 0.8776 - loss: 0.3476 - val_accuracy: 0.7901 - val_loss: 0.5801\n","Epoch 7/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.8898 - loss: 0.3228\n","Epoch 7: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 916ms/step - accuracy: 0.8897 - loss: 0.3228 - val_accuracy: 0.7896 - val_loss: 0.6114\n","Epoch 8/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873ms/step - accuracy: 0.8914 - loss: 0.3177\n","Epoch 8: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 937ms/step - accuracy: 0.8913 - loss: 0.3178 - val_accuracy: 0.7910 - val_loss: 0.6205\n","Epoch 9/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885ms/step - accuracy: 0.8953 - loss: 0.3027\n","Epoch 9: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 948ms/step - accuracy: 0.8953 - loss: 0.3028 - val_accuracy: 0.7892 - val_loss: 0.6433\n","Epoch 10/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - accuracy: 0.8986 - loss: 0.2902\n","Epoch 10: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 930ms/step - accuracy: 0.8985 - loss: 0.2902 - val_accuracy: 0.7846 - val_loss: 0.6860\n","Epoch 11/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874ms/step - accuracy: 0.9031 - loss: 0.2871\n","Epoch 11: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 938ms/step - accuracy: 0.9031 - loss: 0.2872 - val_accuracy: 0.7826 - val_loss: 0.6936\n","Epoch 12/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872ms/step - accuracy: 0.9033 - loss: 0.2768\n","Epoch 12: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 935ms/step - accuracy: 0.9032 - loss: 0.2768 - val_accuracy: 0.7839 - val_loss: 0.6854\n","Epoch 13/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.9034 - loss: 0.2663\n","Epoch 13: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 916ms/step - accuracy: 0.9034 - loss: 0.2663 - val_accuracy: 0.7819 - val_loss: 0.7292\n","Epoch 14/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866ms/step - accuracy: 0.9126 - loss: 0.2534\n","Epoch 14: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 929ms/step - accuracy: 0.9126 - loss: 0.2534 - val_accuracy: 0.7846 - val_loss: 0.7525\n","Epoch 15/15\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875ms/step - accuracy: 0.9151 - loss: 0.2448\n","Epoch 15: val_accuracy did not improve from 0.79986\n","\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 940ms/step - accuracy: 0.9151 - loss: 0.2449 - val_accuracy: 0.7851 - val_loss: 0.7859\n","\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - accuracy: 0.7741 - loss: 0.8235\n","Test Loss: 0.8127340078353882\n","Test Accuracy: 0.7784246206283569\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Compute class weights\n","class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n","class_weights_dict = dict(enumerate(class_weights))\n","\n","# Define your neural network model\n","model = Sequential()\n","model.add(Embedding(input_dim=max_words, output_dim=128))\n","model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n","model.add(Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3)))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3, activation='softmax'))\n","\n","# Compile your model with a lower learning rate\n","optimizer = Adam(learning_rate=0.0005)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Define the filepath for saving the model\n","filepath = \"best_model.keras\"\n","\n","# Define the ModelCheckpoint callback\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","# Train your model with the ModelCheckpoint callback\n","history = model.fit(X_train, y_train, batch_size=64, epochs=15, validation_split=0.2, class_weight=class_weights_dict, callbacks=[checkpoint])\n","\n","# Evaluate your model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T15:14:35.247346Z","iopub.status.busy":"2024-04-11T15:14:35.246539Z","iopub.status.idle":"2024-04-11T15:14:35.417829Z","shell.execute_reply":"2024-04-11T15:14:35.416485Z","shell.execute_reply.started":"2024-04-11T15:14:35.247305Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n","Predicted Sentiment: neutral\n"]}],"source":["# Function to preprocess a single text\n","def preprocess_single_text(text):\n","    stop_words = set(stopwords.words('english'))\n","\n","    # Remove HTML tags\n","    text = BeautifulSoup(text, 'html.parser').get_text()\n","\n","    # Remove URLs\n","    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n","\n","    # Tokenize text\n","    tokenizer = TweetTokenizer()\n","    tokens = tokenizer.tokenize(text)\n","\n","    # Remove emails\n","    tokens = [token for token in tokens if not re.match(r'\\S+@\\S+', token)]\n","\n","    # Remove new lines characters\n","    tokens = [token for token in tokens if token != '\\n']\n","\n","    # Remove distracting single quotes\n","    tokens = [token.replace(\"'\", \"\") for token in tokens]\n","\n","    # Remove all punctuation signs and stopwords\n","    tokens = [token.lower() for token in tokens if token.isalnum() and token.lower() not in stop_words]\n","\n","    # Detokenize text\n","    preprocessed_text = ' '.join(tokens)\n","\n","    return preprocessed_text\n","\n","# Preprocess a single text\n","text_to_classify = \"I stayed at this hotel for a night and it was neither great nor terrible. The room was clean and comfortable, but the amenities were nothing special. It served its purpose for a short stay.\"\n","preprocessed_text = preprocess_single_text(text_to_classify)\n","\n","# Tokenize and pad the preprocessed text\n","sequence = tokenizer.texts_to_sequences([preprocessed_text])\n","padded_sequence = pad_sequences(sequence, maxlen=max_len)\n","\n","# Predict the sentiment class\n","predicted_class = np.argmax(model.predict(padded_sequence), axis=-1)[0]\n","\n","# Map predicted class to sentiment label\n","sentiment_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n","predicted_sentiment = sentiment_mapping[predicted_class]\n","\n","print(\"Predicted Sentiment:\", predicted_sentiment)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4771766,"sourceId":8083879,"sourceType":"datasetVersion"},{"datasetId":4775453,"sourceId":8089166,"sourceType":"datasetVersion"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
